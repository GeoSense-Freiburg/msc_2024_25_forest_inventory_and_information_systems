---
title: "uav_lidar_inventory pt. 3"
author: "Teja Kattenborn (teja.kattenborn@geosense.uni-freiburg.de); Maximilian Fabi (maximilian.fabi@geosense.uni-freiburg.de)"
web: "https://www.geosense.uni-freiburg.de"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
format:
  html:
    code-block-bg: true
    self-contained: true
  pdf:
    df-print: kable
execute:
  echo: true
  warning: false
editor: visual
---

# LiDAR Forest Inventory - Part 3

## Main contents of this exercise

-   Compare Terrestrial Laser Scanning (TLS)-based and Unmanned Aerial Vehicle (UAV)-based point clouds for forest inventries.

-   Compare UAV and TLS-based instance segmentations to a full forest inventory of the [ECOSENSE](https://ecosense.uni-freiburg.de/) site (Ettenheim, Germany).

-   Instance segmentations delineate individual trees in point clouds. Here, we test [SegmentAnyTree](https://github.com/SmartForest-no/SegmentAnyTree). A small visual recap on SegmentAnyTree, a tool to segment individual trees in LiDAR point clouds across different LiDAR data types:

    ![](images/Screenshot 2024-12-17 205528.png)

-   Moreover, we will look into AI-based tree species recognition that was applied on the invidiual tree segmentations.

Remember that we looked into how the point clouds of ULS and TLS differ from one another, here is a quick reminder which shows the two side by side:

![](images/clipboard-2865242693.png)

## Load Packages, paths, etc...

```{r}
#install.packages(c("lidR","terra", "dplyr", "viridis))
library(lidR)
library(viridis)
library(dplyr)
library(terra)
```

Reminder: this script assumes that your Quarto document is in the same directory as your data. If this is not the case, consider to set your working directory with `setwd("path/to/your/data/folder/")`.

## Load & inspect the data

### Inventory data

Load the tree inventory data from ECOSENSE (full inventory).\
\*.gpkg stands for geopackage format. We can load that in R using terra as SpatVector object.

```{r}
tree_inv <- vect("tree_inventory_final2.gpkg")
```

```{r}
head(tree_inv)
```

....puh, many attributes. For sure not all of them are useful for this analysis. We will mostly focus on the species, the DBH and of course the geolocation:

```{r}
plot(tree_inv, col = "red")
```

```{r}
# please ignore
#tree_inv_spec <- read.csv("lookup_odk2.csv", sep = ",", header = T)
#tree_inv2 <- merge(tree_inv, tree_inv_spec, by.x = "species", by.y = "abbr")
#writeVector(tree_inv2, "D:/output_file.gpkg", filetype = "GPKG")
```

### TLS & UAV-based inventory data

UAV-based point clouds with AI-based tree segmentation

```{r}
pc_uav <- readLAS("uav_pointcloud_red.las")
pc_uav
```

TLS-based point clouds with AI-based tree segmentation

```{r}
pc_tls <- readLAS("tls_pointcloud_red.las")
pc_tls
```

Let´s plot the data for a visual comparison:

```{r eval = FALSE}
col <- sample(viridis(2070, option = "mako"))
p <- plot(pc_uav, color = "PredInstance", pal = col, legend = F, axis = T, nbreaks = length(col))
```

```{r eval = FALSE}
col <- sample(viridis(2070, option = "mako"))
p <- plot(pc_tls, color = "PredInstance", pal = col, legend = F, axis = T, nbreaks = length(col))
```

## UAV-based segmentation vs full inventory

Remember how we extracted the tree cordinates in the previous exercise? We will apply this again.

Normalize point cloud on Z-axis

```{r}
mycsf <- csf(TRUE, 1, 1, time_step = 1)
pc_uav <- classify_ground(pc_uav, mycsf)
pc_uav_n <- normalize_height(pc_uav, knnidw())

```

```{r eval = FALSE}
plot(pc_uav_n, axis = T)
```

Cut a horizonal transect for stem extraction (we slice the point cloud close to the ground).

```{r}
pc_uav_n_trans <- filter_poi(pc_uav_n, Z >= 0.1 & Z <= 4)
col <- sample(viridis(2070, option = "mako"))
```

```{r eval = FALSE}
plot(pc_uav_n_trans, color = "PredInstance", pal = col, legend = F, axis = T, nbreaks = length(col))
```

Derive the centroids for stems (as proxy for the tree position):

```{r}
# Calculate centroids for each instance
centroids_uav <- pc_uav_n_trans@data %>%
  group_by(PredInstance) %>%
  summarize(
    X = mean(X),
    Y = mean(Y),
    Z = 0,
    species = as.integer(names(which.max(table(species_id)))),
    .groups = "drop"  # Avoid unnecessary grouping in the result
  )

# Print centroids
print(centroids_uav)
```

Convert the centroids to a geospatial vector format (SpatVector), so we can compare it with the inventory data (which is also in vector format):

```{r}
centroids_uav_sv <- vect(centroids_uav, geom = c("X", "Y"), crs = "EPSG:32632")
```

Visually compare the UAV-based centroids with the inventory data

```{r}
plot(centroids_uav_sv)
points(tree_inv, col = "red")
```

Quantitatively compare the UAV-based centroids with the inventory data

```{r}
buffer_tree_inv <- buffer(tree_inv, width = 1)
plot(buffer_tree_inv)
points(tree_inv, col = "red")
```

```{r}
matches_uav <- intersect(buffer_tree_inv, centroids_uav_sv)
```

```{r}
plot(tree_inv, col = "red")
points(matches_uav, col = "blue", cex = 1.3)

```

```{r}
nrow(matches_uav)/nrow(tree_inv)*100
```

Is there a systematic bias in the detection?

```{r}
unmatched_uav <- buffer_tree_inv[!(buffer_tree_inv$TreeID %in% matches_uav$TreeID), ]
```

```{r}
par(mfrow = c(1,2))
hist(as.numeric(matches_uav$tls_DBH),
     xlim = c(0,0.9),
     ylim=c(0,200),
     main = "DBH matched",
     xlab = "DBH [cm]")
hist(as.numeric(unmatched_uav$tls_DBH),
     xlim = c(0,0.9),
     ylim=c(0,200),
     main = "DBH unmatched",
     xlab = "DBH [cm]")
```

Not all trees are matched, but at least there seems to be no strong bias for small/large trees.

## TLS-based segmentation vs full inventory

Same procedure as for the UAV data. First, we normalize the point cloud...

```{r}
mycsf <- csf(TRUE, 1, 1, time_step = 1)
pc_tls <- classify_ground(pc_tls, mycsf)
pc_tls_n <- normalize_height(pc_tls, knnidw())

```

```{r eval = FALSE}
plot(pc_tls_n, axis = T)
```

... create a transect of stems...

```{r}
pc_tls_n_trans <- filter_poi(pc_tls_n, Z >= 0.1 & Z <= 4)
col <- sample(viridis(2070, option = "mako"))
```

```{r eval = FALSE}
plot(pc_tls_n_trans, color = "PredInstance", pal = col, legend = F, axis = T, nbreaks = length(col))
```

... find the centroids of the stems.

```{r}
# Calculate centroids for each instance
centroids_tls <- pc_tls_n_trans@data %>%
  group_by(PredInstance) %>%
  summarize(
    X = mean(X),
    Y = mean(Y),
    Z = 0,
    species = as.integer(names(which.max(table(species_id)))),
    .groups = "drop"  # Avoid unnecessary grouping in the result
  )

# Print centroids
print(centroids_tls)
```

Let´s compare the result to the inventory data:

```{r}
centroids_tls_sv <- vect(centroids_tls, geom = c("X", "Y"), crs = "EPSG:32632")
```

```{r}
plot(centroids_tls_sv)
points(tree_inv, col = "red")
```

```{r}
buffer_tree_inv <- buffer(tree_inv, width = 1)
plot(buffer_tree_inv)
points(tree_inv, col = "red")
```

```{r}
matches_tls <- intersect(centroids_tls_sv, buffer_tree_inv)
```

```{r}
plot(buffer_tree_inv)
points(matches_tls, col = "blue")
```

```{r}
nrow(matches_tls)/nrow(tree_inv)*100
```

## TLS & UAV tree height comparison

Above we have looked at the coordinates. But we know that we can extract much more, such as the height.

Extract maximum Z value per instance for both TLS and UAV data:

```{r}
# Find the highest point for each instance
uav_tree_heights <- pc_uav_n@data %>%
  group_by(PredInstance) %>%
  slice_max(Z, n = 1) %>%  # Get the row with the maximum Z value for each instance
  ungroup()

uav_tree_heights <- uav_tree_heights[, c("X", "Y", "Z", "PredInstance")]

# View the results
print(uav_tree_heights)
```

```{r}
# Find the highest point for each instance
tls_tree_heights <- pc_tls_n@data %>%
  group_by(PredInstance) %>%
  slice_max(Z, n = 1) %>%  # Get the row with the maximum Z value for each instance
  ungroup()

tls_tree_heights <- tls_tree_heights[, c("X", "Y", "Z", "PredInstance")]

# View the results
print(tls_tree_heights)
```

Let´s compare this visually using histograms:

```{r}
par(mfrow = c(1,2))
hist(tls_tree_heights$Z, ylim = c(0,900), main = "TLS-based height distribution")
hist(uav_tree_heights$Z, ylim = c(0,900), main = "UAV-based height distribution")
```

```{r}
paste("number TLS-based trees: ", nrow(tls_tree_heights))
print("TLS-based tree heights")
summary(tls_tree_heights$Z)
```

```{r}
paste("number UAV-based trees: ", nrow(uav_tree_heights))
print("UAV-based tree heights")
summary(uav_tree_heights$Z)
```

When looking at the transects ... can you explain the results?

![](images/clipboard-2865242693.png)

## AI-based Species identification

-   We will test `DetailView` from Julian Frey et al.: <https://github.com/JulFrey/DetailView>

-   You can read on the details here: [Puliti, S., Lines, E. R., Müllerová, J., Frey, J., Schindler, Z., Straker, A., \... & Astrup, R. (2024). Benchmarking tree species classification from proximally-sensed laser scanning data: introducing the FOR-species20K dataset. *arXiv preprint arXiv:2408.06507*.](https://arxiv.org/abs/2408.06507)

-   Detail view requires point clouds of invidiual trees. Thus, we are perfectly prepared as with [SegmentAnyTree](https://github.com/SmartForest-no/SegmentAnyTree), we already extracted single trees. Here you can see some of the training data of DetailView:\
    ![](images/Screenshot 2024-12-17 1632072.png)

-   Currently, DetailView is one of the most accurate tree species classifiaction modelds for LiDAR data:

![](images/Screenshot%202024-12-17%20163207.png)

Let´s first have look at the reality (forest inventory data of ECOSENSE):

```{r}
par(mar = c(5, 15, 2, 5))
barplot(sort(table(tree_inv$species_name)), las = 1, horiz = T)
```

The UAV- and TLS-based predictions come in species-codes, not species names. So we first load a look up table to attach (merge) the actual names to our data:

```{r}
species_ai <- read.csv("lookup_ai.csv")
```

... attach the species name to the point clouds....

```{r}
pc_tls@data <- merge(pc_tls@data, species_ai, by = "species_id", all.x = TRUE)
pc_uav@data <- merge(pc_uav@data, species_ai, by = "species_id", all.x = TRUE)
```

... and to the extract stem coordinates (centroids):

```{r}
centroids_tls_sv2 <- merge(centroids_tls_sv , species_ai, by.x ="species", by.y = "species_id", all.x = TRUE)
centroids_uav_sv2 <- merge(centroids_uav_sv , species_ai, by.x ="species", by.y = "species_id", all.x = TRUE)
```

### Visual comparison of the species classification

```{r eval = FALSE}
p <- plot(pc_tls, color = "species_id", legend = T, axis = T)
p <- plot(pc_uav, color = "species_id", legend = T, axis = T)
```

Okay, the results "look" already quite different. Let´s check the stats:

```{r}
uav_n_spec <- pc_uav@data %>%
  as.data.frame() %>%
  group_by(species) %>%
  summarise(number_of_instances = n_distinct(PredInstance)) %>%
  arrange(desc(number_of_instances))

uav_n_spec
```

```{r}
tls_n_spec <- pc_tls@data %>%
  as.data.frame() %>%
  group_by(species) %>%
  summarise(number_of_instances = n_distinct(PredInstance)) %>%
  arrange(desc(number_of_instances))

tls_n_spec
```

sort(table(pc_tls\$species))

```{r}
par(mar = c(10, 5, 2, 5))

# Convert species to a named vector
species_counts <- setNames(tls_n_spec$number_of_instances, tls_n_spec$species)

# Create the barplot
barplot(species_counts,
        las = 2,              # Rotate axis labels for readability
        col = "skyblue",      # Add some color
        main = "Species numbers from TLS data",  # Add a title
        ylab = "Number of Instances")  # Add Y-axis label
```

```{r}
par(mar = c(10, 5, 2, 5))

# Convert species to a named vector
species_counts <- setNames(uav_n_spec$number_of_instances, uav_n_spec$species)

# Create the barplot
barplot(species_counts,
        las = 2,              # Rotate axis labels for readability
        col = "skyblue",      # Add some color
        main = "Species numbers from UAV data",  # Add a title
        ylab = "Number of Instances")  # Add Y-axis label
```

### Compare the tree species distribution among datasets:

```{r}

# Extract unique species across all SpatVectors
all_species <- unique(c(tree_inv$species_name, centroids_tls_sv2$species.y, centroids_uav_sv2$species.y))

tree_inv$species.y <- tree_inv$species_name

# Create a color palette for all species
species_colors <- setNames(rainbow(length(all_species)), all_species)

# Function to assign colors based on species
get_colors <- function(spatvector, color_mapping) {
  color_mapping[spatvector$species.y]
}

# Adjust layout to include space for the legend
par(mfrow = c(1, 3), mar = c(4, 4, 2, 1))  # 2x2 grid, adjust margins as needed


plot(tree_inv, 
     col = get_colors(tree_inv, species_colors), 
     main = "Inventory",
     legend = FALSE)

plot(centroids_tls_sv2, 
     col = get_colors(centroids_tls_sv2, species_colors), 
     main = "Species by TLS",
     legend = FALSE)

plot(centroids_uav_sv2, 
     col = get_colors(centroids_uav_sv2, species_colors), 
     main = "Species by UAV",
     legend = FALSE)

```

```{r}
par(mfrow = c(1, 3), mar = c(1, 4, 1, 1))
plot.new()  # Create an empty plot for the legend
legend("center", legend = names(species_colors), fill = species_colors, title = "Species")
```

## Open Questions & Outlook

-   How could we potentially improve the tree species classification?

-   Can we trust UAV-based or TLS-based inventories?

-   Can we trust field-based inventories in terms of coverage, sampling and measurement uncertainty?

-   What are related advantages or disadvantages?

-   How can we move on with UAV- or TLS-based inventories to estimate basal area, biomass or timber volume?

-   How will forest inventories look like in 2050?
